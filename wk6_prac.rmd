---
title: "wk6_prac"
output: html_document
date: "2025-11-11"
---

library packages
```{r}
#first library a few packages that we will use during the practical
#note you may need to install them first...
#install.packages("ggspatial")
#install.packages("prettymapr")
library(spatstat)
library(here)
library(sp)
library(tmap)
library(sf)
library(tmaptools)
library(stringr)
library(tidyverse)
library(sf)
library(fpc)
library(dbscan)
library(ggplot2)
library(ggspatial)
library(prettymapr)
```
 
 
 
 raed the london data
```{r}
##First, get the London Borough Boundaries
LondonBoroughs <- st_read("/Users/levine/Desktop/CASA/GIS/wk1/statistical-gis-boundaries-london/ESRI/London_Borough_Excluding_MHW.shp")
```
 
 
 
```{r}
BoroughMap <- LondonBoroughs %>%
  dplyr::filter(str_detect(GSS_CODE, "^E09"))%>%
  st_transform(., 27700)

qtm(BoroughMap)
```
```{r}
summary(BoroughMap)
```


load the London blue plaques data online
```{r}
##Now get the location of all Blue Plaques in the City
BluePlaques <- st_read("https://s3.eu-west-2.amazonaws.com/openplaques/open-plaques-london-2018-04-08.geojson")
```
```{r}
summary(BluePlaques)
```
 
 
 plot the blue plaques on the map of London
```{r}
#plot the blue plaques in the city
tmap_mode("plot")

tm_shape(BoroughMap) +
  tm_polygons(fill_alpha = 0.5)+
tm_shape(BluePlaques) +
  tm_dots(fill = "blue", size=0.1)
```
 

remove the blue plaques which have the same location
```{r}
#remove duplicates
BluePlaques <- distinct(BluePlaques)
```
 
 
transfer the CRS of BluePlaques to the same with BoroughMap
```{r}

BluePlaques <- st_transform(BluePlaques, st_crs(BoroughMap))
```



only select the blue plaques in the London (by the second operator is blank , , - this controls which attributes are kept)
```{r}
BluePlaquesSub <- BluePlaques[BoroughMap,]

#plot the blue plaques in the city
tmap_mode("plot")

#check to see that they've been removed
tm_shape(BoroughMap) +
  tm_polygons(fill_alpha = 0.5)+
tm_shape(BluePlaquesSub) +
  tm_dots(fill = "blue", size=0.1)
```

different method to do that
```{r}
# add sparse=false to get the complete matrix.
# this is the same as select by location in QGIS
# filter from dplyr is the same as select by attribute 
intersect_indices <-st_intersects(BoroughMap, BluePlaques)
```
 
 
 
 
in order to speed up the analysis and comparation, we first choose the one that have less blue plaques, which is Harrow
```{r}
#extract the borough

# select by attribute
Harrow <- BoroughMap %>%
  filter(., NAME=="Harrow")

#Check to see that the correct borough has been pulled out
tm_shape(Harrow) +
  tm_polygons(col = NA, fill_alpha = 0.5)
```

Then choose only blue plaques in certain area, Harrow in this time
```{r}
#clip the data to our single borough
BluePlaquesSub <- BluePlaques[Harrow,]



#check that it's worked
tm_shape(Harrow) +
  tm_polygons(fill_alpha = 0.5)+
tm_shape(BluePlaquesSub) +
  tm_dots(fill = "blue", size=0.1)
```

now we can use spatstat to do analysis.

First, creat a observation windon using Harrow boundary:
```{r}
#now set a window as the borough boundary
window <- as.owin(Harrow)
plot(window)
```


For point pattern analysis, we need to create a point pattern (ppp) object
```{r}
#create a sp object
BluePlaquesSub<- BluePlaquesSub %>%
  as(., 'Spatial')
#create a ppp object
BluePlaquesSub.ppp <- ppp(x=BluePlaquesSub@coords[,1],
                          y=BluePlaquesSub@coords[,2],
                          window=window)
```


have a look at the new ppp object
```{r}
BluePlaquesSub.ppp %>%
  plot(.,pch=16,cex=0.5, 
       main="Blue Plaques Harrow")
```

produce a Kernel Density Estimation (KDE) map from a ppp object using the density() function.
```{r}
BluePlaquesSub.ppp %>%
  density(., sigma=500) %>%
  plot()
```

The sigma value sets the diameter of the Kernel, try different sigma value:
```{r}
BluePlaquesSub.ppp %>%
  density(., sigma=1000) %>%
  plot()
```


carry out a simple quadrat analysis on our data using the quadrat count function in spatstat to understand the Poisson distribution (not recommended in real analysis)
```{r}
#First plot the points
plot(BluePlaquesSub.ppp,
     pch=16,
     cex=0.5, 
     main="Blue Plaques in Harrow")

#now count the points in that fall in a 6 x 6
#grid overlaid across the windowBluePlaquesSub.ppp2<-BluePlaquesSub.ppp %>%
BluePlaquesSub.ppp %>%
  quadratcount(.,nx = 6, ny = 6)%>%
    plot(., add=T, col="red")
```


comparing our observed distribution of points with a statistically likely (Complete Spatial Random) distibution, based on the Poisson distribution.

Using the same quadratcount() function again, save into a table
```{r}
#run the quadrat count
Qcount <- BluePlaquesSub.ppp %>%
  quadratcount(.,nx = 6, ny = 6) %>%
  as.data.frame() %>%
  dplyr::count(Var1=Freq)%>%
  dplyr::rename(Freqquadratcount=n)
```

check the type of first row, to see if it's numeric
```{r}
Qcount %>% 
  summarise_all(class)
```

calculate the poisson distribution expected values 
```{r}
sums <- Qcount %>%
  #calculate the total blue plaques (Var * Freq)
  mutate(total = Var1 * Freqquadratcount) %>%
  dplyr::summarise(across(everything(), sum))%>%
  dplyr::select(-Var1) 

lambda<- Qcount%>%
  #calculate lambda
  mutate(total = Var1 * Freqquadratcount)%>%
  dplyr::summarise(across(everything(), sum)) %>%
  mutate(lambda=total/Freqquadratcount) %>%
  dplyr::select(lambda)%>%
  pull(lambda)
```


Calculate expected using the Poisson formula from above k is the number of blue plaques counted in a square and is found in the first column of our table
```{r}
QCountTable <- Qcount %>%
  mutate(Pr=((lambda^Var1)*exp(-lambda))/factorial(Var1))%>%
  #now calculate the expected counts based on our total number of plaques
  #and save them to the table
  mutate(Expected= (round(Pr * sums$Freqquadratcount, 0)))

#Compare the frequency distributions of the observed and expected point patterns
plot(c(1,5),c(0,14), type="n",
xlab="Number of Blue Plaques (Red=Observed,Blue=Expected)", 
     ylab="Frequency of Occurances")
points(QCountTable$Freqquadratcount, 
       col="Red", 
       type="o", 
       lwd=3)
points(QCountTable$Expected, col="Blue", 
       type="o", 
       lwd=3)
```

to make sure, use the quadrat.test() function which built into spatstat, to determines if there is an association between two categorical variables. If p-value is > 0.05 then this indicates that we have CSR and there is no pattern in our points

```{r}
teststats <- quadrat.test(BluePlaquesSub.ppp, nx = 6, ny = 6)
```
```{r}
plot(BluePlaquesSub.ppp,pch=16,cex=0.5, main="Blue Plaques in Harrow")
plot(teststats, add=T, col = "red")
```
Try running a quadrant analysis for different grid arrangements (2 x 2, 3 x 3, 10 x 10 etc.)



Then we can conduct a Ripley’s K test on our data very simply with the spatstat package using the kest() function
```{r}
K <- BluePlaquesSub.ppp %>%
  Kest(., correction="border") %>%
  plot()
```
we can see until distances of around 1300 metres, Blue Plaques appear to be clustered in Harrow
```{r}
# we can also extract the plot into a dataframe
Kval <- as.data.frame(Kest(BluePlaquesSub.ppp, correction = "Ripley"))
```



carry out a DBSCAN analysis of blue plaques in my borough to see if there are any clusters present:
```{r}
#first check the coordinate reference system of the Harrow spatial polygon:
st_geometry(BoroughMap)
```
Base on the result of Ripley's K, it seems get clustering around 1200m, with the largest bulge in the graph at around 700m, so it's great to start at 700m.
begin by searching for clusters of at least 4 points
```{r}
#first extract the points from the spatial points data frame
BluePlaquesSubPoints <- BluePlaquesSub %>%
  coordinates(.)%>%
  as.data.frame()

#now run the dbscan analysis
db <- BluePlaquesSubPoints %>%
  fpc::dbscan(.,eps = 700, MinPts = 4)

#now plot the results
plot(db, BluePlaquesSubPoints, main = "DBSCAN Output", frame = F)
plot(BoroughMap$geometry, add=T)
```
could also use kNNdistplot() from the dbscan package to find a suitable eps value based on the ‘knee’ in the plot
```{r}
# used to find suitable eps value based on the knee in plot
# k is no of nearest neighbours used, use min points
BluePlaquesSubPoints%>%
  dbscan::kNNdistplot(.,k=4)
```
DBSCAN analysis shows that for these values of eps and MinPts there are three clusters in the area I am analysing. eps 和 MinPts 的值会有影响

now make a better graph
```{r}
db
db$cluster
```

 add this cluster membership info back into our dataframe
```{r}
BluePlaquesSubPoints<- BluePlaquesSubPoints %>%
  mutate(dbcluster=db$cluster)
```

Next,
1.convert this dataframe to an sf object
2.make convex hulls around the clusters
```{r}
# convert the data frame to sf
BluePlaquesSubPoints_sf <- st_as_sf(BluePlaquesSubPoints, 
                                    coords = c("coords.x1", "coords.x2"), 
                                    crs = 27700)

# make the convex hulls around the cluster points
chull_polygons <- BluePlaquesSubPoints_sf %>%
  # remove any points not in a cluster
  filter(dbcluster>0)%>%
  group_by(dbcluster) %>%
  summarise(geometry = st_combine(geometry)) %>%  # combine points
  mutate(geometry = st_convex_hull(geometry)) %>% # convex hull
  st_as_sf()
```
3.plot
-fill is for the interior colour (e.g. polygons)
-color is for borders and points
```{r}
# Create the map
ggplot() +
  annotation_map_tile(zoom = 13) +
  geom_sf(data = BluePlaquesSubPoints_sf, aes(color=dbcluster), size = 3)+
  geom_sf(data = chull_polygons, aes(fill = dbcluster), 
          alpha = 0.8, 
          # remove polygon borders
          color = NA, 
          show.legend = FALSE) +

  theme_bw()
```

